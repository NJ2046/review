# ReviewPerformance
复盘性能调优事件始末
# 前置介绍
## 业务背景
AI部门与社交部门联合执行,赋予产品智能化.社交业务出现分流现象,即分流到微信,邮箱以及其他沟通交流软件.AI部门提供图片文字识别服务,社交部门将得到的文字通过规则限制用户分流.
## 实现技术
yolo,tensfolw,keras,touch,tfserving,thrift,kafka,canal,hbase,docker,java,python.
## 生产流程
### 角色
算法工程师,python工程师,java工程师,项目经理
### 角色职能
1. 算法工程师:根据任务内容,查阅论文或开源项目等,选择符合任务的机器学习平台以及相应的网络结构,获取数据集,定义相关函数,训练模型,loss值收敛,停止训练,评估模型,达到标准,发布模型,根据情况,添加相应的预处理和后处理.
### 流程
算法工程师训练模型发布模型，添加预处理或后处理函数，将相关代码，通过钉钉转交给python工程师，口头沟通，获知代码运行pip requirements．
python工程师，关闭转交代码中不必要的测试输出，调试pip包依赖，关闭代码中show image函数，最后保证代码正常运行，结果准确．构建tfserving docker,thrift docker, kafka docker, 模型发布存放于tfserving,　模型预处理后处理以及模型使用存放与thrift，业务使用存放于kafka．通过kafka与java工程师交接．
java工程师，向指定话题推入约定好格式的json数据，通过指定话题拉出约定好的格式的json数据．交接过程是，数据格式文档化，由gitlab负责呈现，话题名称未文档化，通过口头交流保持一致性．
### 后记
python工程师模型调试中，输出模型处理时间，优化模型处理时间，将调用tfserving切换成直接调用模型．通过print和time函数来获取相应时间．
# 问题出现
java工程师使用社交软件实时发布一张违规图片，发现未经过规则处理，溯源到python工程师写入指定kafka话题处,报告在写入话题未收到模型处理数据．
# 分析问题
根据数据流向，即把数据当做水流，在指定码头检查数据是否流入，强调数据流的方向．定义TPjava,TPpython，数据流向为TPjava->TPptyon.根据java工程师报告得知，TPpython未收到数据．java工程师的数据流入点非TPjava，即首先确认TPjava是否流入数据,与java工程师沟通，获知从源数据产生以及验证TPjava获知数据的方法．使用java工程师的手机，打开gagahi软件，向任意用户发送"京城按摩师　13402358890 wx 779229740"，开始监听TPjava话题，查看是否接收到相应数据．验证后，确认数据已经流入TPjava，开始审查kafka docker代码，发现数据处理速度异常缓慢，6分钟处理一条数据,根据经验得知，监听TPjava和写入TPpython程序已经运行时间超过12个小时．
## review
根据数据流向确认问题,步步验证,这个比较好;手动点击发送,眼睛监听终端输出,确认TPjava和TPpytohn数据流入,这种方法不好,后续可以改进.
## kafka docker
关掉正在运行的kafka docekr代码,重新启动,通过gagahi软件传入京城按摩师图片,观察TPjava和TPpython话题,均流入数据,报告java工程师,验证后续java工程师的数据流向,正常.基本得出,数据从TPjava流入到TPpython的速度随着时间的增加而增加.对比分析速度变慢的源头,在kafka docker请求人脸检测,字符识别和性别检测模型,10次,50次,100次,500次;在thrift docker请求人脸检测,字符识别和性别检测模型,10次,50次,100次,500次.对比分析增长速度.性别检测在kafka docker端随着请求次数的变化,平均处理时间不变,即增长速度为0,性别检测在thrift docker端同kafka docker端;以同样的方法对比分析人脸检测模型和字符识别模型,得出,平均时间随着请求次数增加而增加,即增长速度大于0,对比分析kafka和thrift增长速度,基本相同.由此得出结论,排除速度增长出现的原因在kafka docker中.
### review
提出问题在计划之外,从其他任务切换到这里,很多行为未经过思考和计划,基本属于,快速思考快速响应,优点是快,缺点是思考不多,可能要回来,或者错过关键信息.快速响应,先让TPpython得到正确处理的数据,故杀死进程重新启动,这也是保证程序准确性的做法.后续依照数据流向问题,来溯源问题根源,在比对分析中使用了cProfile工具,可以按照时间输出所有函数运行时间,调用次数以及平均时间等信息.刚开始使用眼睛来查看每个函数运行所花费的时间,后来用flameprof和cProfile结合,将函数耗时可视化.
## thrift docker
编写thrift docker中debug代码,使用cProfile和flameprof进行10,100,1000次调用的火焰图分析,聚焦在人脸检测模型处理函数中,不同的次数,各个函数运行时间占总运行时间不同;10次的时候,tfserving,yolo和sess.run中比例为2:4:4,100次的时候为2:3:5;在1000次的时候耗时比例是0.5:0,8:8.7.后来准备改进sess.run函数,使用close和with sess等,均没有效果.算法工程师建议使用进程打开session.run函数,进程结束将会释放资源,未验证.基本可以定位于模型后处理时间较长.
### review
行动中,记录函数运行时间信息写在了本子上,未形成书面化;对cProfile和FlameGraphs为深入了解;以及处理时间递增问题,本质是没有找到.
# 整体梳理和规划
## 整体
1. 角色缺失:产品经理,测试工程师,运维工程师
2. 角色交接:角色交接规范化,依照事件流,制作各角色之间的准入标准,可由产品经理结合测试工程师完成,即产品经理与各个角色开发获知准入,交由测试工程师,测试在每个角色阶段性完成后,进行测试,交由下游角色.这样保证角色交接间的低耦合,不用验证上游问题或者下游问题.
## 个人
- 角色:python工程师
- 沟通:认真听对方的表述,试着去理解,不懂的地方,多思考,不要太在意自己的看法,在意你能从对方表述中获得什么,将有利于事物发展的记录下来,进行验证.
- 思考和行动:思考和行动是矛盾的,如果多想,就必定会使得行动变得缓慢,如果行动多一些,必定思考问题不够深度.这个问题,需要找到思考和行动的切换点,即定义思考和行动为T和A,单位时间内,T和A的交替时间,针对不同问题,找到合适自己大脑的切换点.
## 工程继续走
- 如何解决session.run在更多次调用中占总时间比如高的问题
- 确定是哪个方面导致增量时间.初步方案,动态监控:cpu,mem,gpu,gm,io,在函数上消耗的时间;在资源未饱和的情况下,程序为什么越跑越慢?
- 模型缓慢的情形下使用工程方案来提高模型速度.初步方案,解析session.run内部执行逻辑,分成块,用多线程调用,最后合在一起.用底层语言,来重写session.run,提高速度.需要认识后,再分析为什么这块会慢.
## 候选方案
- 拿来:使用现有的API接口,比如百度,腾讯等,节省成本的前提,将事情完成.
- 半拿来:使用开源社区,已经训练好的模型,快速评估准确性和性能,快速部署,快速使用,将事情完成
- 自研发:重新训练模型,达到准确和性能标准,工程快速应用
# 经验
- 模型的召准与模型性能的平衡,初创时期,可以设置全家桶,也就是尽量多,来了的顾客按需拿取.后期,依旧是快速交付老话题,让需求跑在发布环境.

# 技术积累
```
import cProfile, pstats, io

pr = cProfile.Profile()
pr.enable()

code...

pr.disable()
pr.dump_stats("pipeline.prof")
s = io.StringIO()
# 指定排序的列，降序
sortby = "cumtime"
# 排序
ps = pstats.Stats(pr, stream=s).sort_stats(sortby)
# 输出所有
ps.print_stats()
# 输出前十个
ps.print_stats(10)
print(s.getvalue())


pip install flameprof
python3 /usr/local/lib/python3.6/dist-packages/flameprof.py pipeline.prof  > fdgpu100.svg
```
















